{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Antoine A. Ruzette\n",
    "Date: 2025-02-21\n",
    "\n",
    "This notebook processes cell measurement tables exported from QuPath to plot the spatial distribution of cell-level pixel intensity in relation to a modelled stromal border. It also supports the comparison of confusion matrices between threshold- and machine learning-based cell classification.\n",
    "\n",
    "Contains the code to plot data from images containing four channels: DAPI (nuclei), TRITC (cytokeratin), FITC (fibronectin) and CY5 (Ki67). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install fitter==1.6.0 ipykernel==6.17.1 matplotlib==3.7.2 natsort==8.4.0 numpy==1.26.4 pandas==2.2.2 scipy==1.11.4 seaborn==0.13.2 setuptools==75.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import natsort\n",
    "import re\n",
    "from matplotlib.ticker import LogFormatterSciNotation\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "\n",
    "# colorblind-friendly colors\n",
    "CB_palette = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                '#f781bf', '#a65628', '#984ea3',\n",
    "                '#999999', '#e41a1c', '#dede00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-end functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_files(folder_path, file_paths, expected_columns):\n",
    "    \"\"\"\n",
    "    Load and preprocess CSV files.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing CSV files.\n",
    "        file_paths (list): List of file names.\n",
    "        expected_columns (dict): Dictionary mapping expected column keys to possible names.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of processed DataFrames (one per image).\n",
    "        dict: Column mapping for use in plotting.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    final_column_mapping = {}\n",
    "\n",
    "    for idx, image in enumerate(file_paths):\n",
    "        print(f\"\\n🔹 Processing: {image}\")\n",
    "        file_path = os.path.join(folder_path, image)\n",
    "\n",
    "        # Load CSV to check available columns first\n",
    "        try:\n",
    "            df_sample = pd.read_csv(file_path, nrows=1)\n",
    "            available_columns = df_sample.columns.tolist()\n",
    "            print(f\"✅ Available Columns: {available_columns}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {image}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Dynamically map expected column names to available ones\n",
    "        column_mapping = {}\n",
    "        for key, possible_names in expected_columns.items():\n",
    "            for name in possible_names:\n",
    "                if name in available_columns:\n",
    "                    column_mapping[key] = name\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"⚠️ Warning: {key} column not found in {image}. Skipping.\")\n",
    "\n",
    "        if not column_mapping:\n",
    "            print(f\"⚠️ Skipping {image} as no expected columns were found.\")\n",
    "            continue\n",
    "\n",
    "        # Reload dataframe with only found columns\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, usecols=list(column_mapping.values()))\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading selected columns in {image}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Skip this file if essential columns are missing\n",
    "        essential_columns = [\"DAPI\", \"Ki67_647\"]\n",
    "        missing_essential = [col for col in essential_columns if col not in column_mapping]\n",
    "        if missing_essential:\n",
    "            print(f\"⚠️ Skipping {image} due to missing essential columns: {missing_essential}\")\n",
    "            continue\n",
    "\n",
    "        # Remove outliers dynamically (only for present columns)\n",
    "        outlier_limits = {}\n",
    "        for key in [\"DAPI\", \"Ki67_647\", \"KER_488\", \"FN_568\"]:\n",
    "            if key in column_mapping:\n",
    "                col_name = column_mapping[key]\n",
    "                p01 = df[col_name].quantile(0.01)\n",
    "                p99 = df[col_name].quantile(0.99)\n",
    "                outlier_limits[col_name] = (p01, p99)\n",
    "\n",
    "        print(f\"📊 Outlier Thresholds: {outlier_limits}\")\n",
    "\n",
    "        # Filter outliers\n",
    "        df_no_outlier = df.copy()\n",
    "        for col, (p01, p99) in outlier_limits.items():\n",
    "            df_no_outlier = df_no_outlier[(df_no_outlier[col] >= p01) & (df_no_outlier[col] <= p99)]\n",
    "\n",
    "        if df_no_outlier.empty:\n",
    "            print(f\"⚠️ Skipping {image} as it became empty after outlier removal.\")\n",
    "            continue\n",
    "\n",
    "        # Add a column to track which image this data comes from\n",
    "        df_no_outlier[\"Image\"] = f\"{idx+1}G\"\n",
    "\n",
    "        dfs.append(df_no_outlier)\n",
    "\n",
    "        # Save column mapping for later use\n",
    "        final_column_mapping = column_mapping  \n",
    "\n",
    "    if dfs:\n",
    "        return dfs, final_column_mapping\n",
    "    else:\n",
    "        print(\"⚠️ No valid data loaded.\")\n",
    "        return [], {}\n",
    "    \n",
    "\n",
    "# Helper function to generate floating point ranges\n",
    "def frange(start, stop, step):\n",
    "    \"\"\"Generate a range of floats with a given step size.\"\"\"\n",
    "    while start <= stop:\n",
    "        yield start\n",
    "        start += step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell measurement distributions for each channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear scale distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder and file paths\n",
    "folder_path = \"your/folder/path\"\n",
    "\n",
    "file_paths = [\n",
    "    \"data1.csv\",\n",
    "    \"data2.csv\",\n",
    "]\n",
    "\n",
    "# Define bin sizes for each channel\n",
    "bin_sizes = {\n",
    "    \"DAPI\": 50,\n",
    "    \"Ki67_647\": 5,\n",
    "    \"KER_488\": 75,\n",
    "    \"FN_568\": 40\n",
    "}\n",
    "\n",
    "expected_columns = {\n",
    "    \"Class\": [\"Class\"],\n",
    "    \"DAPI\": [\"DAPI: Nucleus: Median\"],\n",
    "    \"KER_488\": [\"FITC KER: Cytoplasm: Median\"],\n",
    "    \"Ki67_647\": [\"CY5 Ki67: Nucleus: Max\"],\n",
    "    \"FN_568\": [\"TRITC FN: Cell: Median\"],\n",
    "    \"Nucleus_Area\": [\"Nucleus: Area µm^2\"]\n",
    "}\n",
    "\n",
    "y_ticks = {\n",
    "    \"DAPI\": [0, 0.005, 0.01, 0.015],\n",
    "    \"KER_488\": [0, 0.01, 0.02, 0.03, 0.04], \n",
    "    \"Ki67_647\": [0, 0.005, 0.01, 0.015, 0.02], \n",
    "    \"FN_568\": [0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "}\n",
    "\n",
    "# Load and preprocess data\n",
    "dfs_data_list, column_mapping = load_and_preprocess_files(folder_path, file_paths, expected_columns)\n",
    "\n",
    "# Ensure data is available before plotting\n",
    "if dfs_data_list:\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(30, 26))\n",
    "\n",
    "    plot_keys = [\"DAPI\", \"Ki67_647\", \"KER_488\", \"FN_568\"]  # Use same keys as column_mapping\n",
    "    axes_positions = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "    axis_limits = {\n",
    "        \"DAPI\": (0, 20000),\n",
    "        \"Ki67_647\": (0, 3000),\n",
    "        \"KER_488\": (0, 20000),\n",
    "        \"FN_568\": (0, 8000)\n",
    "    }\n",
    "\n",
    "    # Descriptive labels for axes\n",
    "    axis_labels = {\n",
    "        \"DAPI\": \"DAPI median nuclear intensity, a.u.\",\n",
    "        \"Ki67_647\": \"Ki67 max nuclear intensity, a.u.\",\n",
    "        \"KER_488\": \"Cytokeratin median cytoplasmic intensity, a.u.\",\n",
    "        \"FN_568\": \"Fibronectin median cellular intensity, a.u.\"\n",
    "    }\n",
    "\n",
    "    plotted_something = False\n",
    "\n",
    "    for df in dfs_data_list:\n",
    "        image_label = df[\"Image\"].iloc[0]  # Get image label\n",
    "\n",
    "        for key, (row, col) in zip(plot_keys, axes_positions):\n",
    "            if key in column_mapping and column_mapping[key] in df.columns:\n",
    "                sns.histplot(\n",
    "                    df[column_mapping[key]],\n",
    "                    binwidth=bin_sizes.get(key, 10),  # Use specified bin size, default to 10 if not found\n",
    "                    kde=True,\n",
    "                    line_kws={\"linewidth\": 5}, \n",
    "                    ax=axs[row, col],\n",
    "                    label=image_label,\n",
    "                    alpha=0.5,\n",
    "                    stat=\"probability\"  # Normalize histogram to show frequency instead of absolute count\n",
    "                )\n",
    "                plotted_something = True\n",
    "\n",
    "    # Set log scale, font sizes, tick sizes, and format plots\n",
    "    for (key, (row, col)) in zip(plot_keys, axes_positions):\n",
    "        ax = axs[row, col]\n",
    "        ax.set_yscale('linear')\n",
    "        ax.set_xscale('linear')\n",
    "        ax.set_ylabel('Probability', fontsize=45)\n",
    "        ax.set_xlabel(axis_labels[key], fontsize=45)\n",
    "        ax.tick_params(axis='both', labelsize=45)\n",
    "\n",
    "        # Limit x-axis range and set 5 ticks\n",
    "        if key in axis_limits:\n",
    "            ax.set_xlim(axis_limits[key])\n",
    "            xticks = [axis_limits[key][0] + i * (axis_limits[key][1] - axis_limits[key][0]) / 4 for i in range(5)]\n",
    "            ax.set_xticks(xticks)\n",
    "\n",
    "        # Set y-ticks if defined\n",
    "        if key in y_ticks:\n",
    "            ax.set_yticks(y_ticks[key])\n",
    "            ax.set_ylim(bottom=min(y_ticks[key]), top=max(y_ticks[key]))\n",
    "\n",
    "        # Format y-tick labels to 2 significant digits\n",
    "        ax.set_yticklabels([f\"{tick:.2g}\" for tick in ax.get_yticks()])\n",
    "\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.savefig(f\"{folder_path}/exploratory_histograms.png\", dpi=300)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ No plots generated due to lack of valid data.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
